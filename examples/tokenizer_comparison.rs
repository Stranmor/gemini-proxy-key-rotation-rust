// examples/tokenizer_comparison.rs

use std::env;
use gemini_proxy::tokenizer;

#[tokio::main]
async fn main() {
    // –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –≤—Å–µ —Ç–æ–∫–µ–Ω–∏–∑–∞—Ç–æ—Ä—ã
    println!("üöÄ –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Ç–æ–∫–µ–Ω–∏–∑–∞—Ç–æ—Ä–æ–≤...");
    
    if let Err(e) = tokenizer::gemini_simple::GeminiTokenizer::initialize().await {
        eprintln!("–û—à–∏–±–∫–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ –ø—Ä–æ—Å—Ç–æ–≥–æ —Ç–æ–∫–µ–Ω–∏–∑–∞—Ç–æ—Ä–∞: {e}");
        return;
    }
    
    if let Err(e) = tokenizer::gemini_calibrated::GeminiCalibratedTokenizer::initialize().await {
        eprintln!("–û—à–∏–±–∫–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ –∫–∞–ª–∏–±—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ —Ç–æ–∫–µ–Ω–∏–∑–∞—Ç–æ—Ä–∞: {e}");
        return;
    }
    
    if let Err(e) = tokenizer::gemini_ml_calibrated::GeminiMLCalibratedTokenizer::initialize().await {
        eprintln!("–û—à–∏–±–∫–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ ML-–∫–∞–ª–∏–±—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ —Ç–æ–∫–µ–Ω–∏–∑–∞—Ç–æ—Ä–∞: {e}");
        return;
    }
    
    println!("‚úÖ –í—Å–µ —Ç–æ–∫–µ–Ω–∏–∑–∞—Ç–æ—Ä—ã –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω—ã\n");
    
    // –¢–µ—Å—Ç–æ–≤—ã–µ —Ç–µ–∫—Å—Ç—ã
    let test_cases = vec![
        "Hello world",
        "Hello, world!",
        "The quick brown fox jumps over the lazy dog.",
        "Hello ‰∏ñÁïå! üåç How are you?",
        "Mathematical symbols: ‚àë, ‚à´, ‚àÇ, ‚àá, ‚àû, œÄ",
        r#"function test() { return 42; }"#,
        r#"{"name": "John", "age": 30}"#,
    ];
    
    println!("üìä –°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Ç–æ–∫–µ–Ω–∏–∑–∞—Ç–æ—Ä–æ–≤:\n");
    println!("{:<50} | {:>8} | {:>12} | {:>15}", "–¢–µ–∫—Å—Ç", "–ü—Ä–æ—Å—Ç–æ–π", "–ö–∞–ª–∏–±—Ä.", "ML-–ö–∞–ª–∏–±—Ä.");
    println!("{:-<50}-+-{:->8}-+-{:->12}-+-{:->15}", "", "", "", "");
    
    for text in test_cases {
        let simple = tokenizer::count_gemini_tokens(text).unwrap_or(0);
        let calibrated = tokenizer::count_calibrated_gemini_tokens(text).unwrap_or(0);
        let ml_calibrated = tokenizer::count_ml_calibrated_gemini_tokens(text).unwrap_or(0);
        
        let display_text = if text.chars().count() > 47 {
            format!("{}...", text.chars().take(44).collect::<String>())
        } else {
            text.to_string()
        };
        
        println!("{display_text:<50} | {simple:>8} | {calibrated:>12} | {ml_calibrated:>15}");
    }
    
    println!("\nüìà –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ —Ç–æ–∫–µ–Ω–∏–∑–∞—Ç–æ—Ä–∞—Ö:");
    
    if let Some(info) = tokenizer::get_gemini_tokenizer_info() {
        println!("‚Ä¢ –ü—Ä–æ—Å—Ç–æ–π: {info}");
    }
    
    if let Some(info) = tokenizer::get_calibrated_gemini_tokenizer_info() {
        println!("‚Ä¢ –ö–∞–ª–∏–±—Ä–æ–≤–∞–Ω–Ω—ã–π: {info}");
    }
    
    if let Some(info) = tokenizer::get_ml_calibrated_gemini_tokenizer_info() {
        println!("‚Ä¢ ML-–ö–∞–ª–∏–±—Ä–æ–≤–∞–Ω–Ω—ã–π: {info}");
    }
    
    // –ï—Å–ª–∏ –µ—Å—Ç—å Google API –∫–ª—é—á, —Å—Ä–∞–≤–Ω–∏–º —Å —Ä–µ–∞–ª—å–Ω—ã–º API
    if let Ok(_api_key) = env::var("GOOGLE_API_KEY") {
        println!("\nüîç –°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Å Google API:");
        
        let test_text = "Hello ‰∏ñÁïå! How are you today?";
        let our_ml = tokenizer::count_ml_calibrated_gemini_tokens(test_text).unwrap_or(0);
        
        println!("–¢–µ—Å—Ç: \"{test_text}\"");
        println!("–ù–∞—à ML-—Ç–æ–∫–µ–Ω–∏–∑–∞—Ç–æ—Ä: {our_ml} —Ç–æ–∫–µ–Ω–æ–≤");
        
        // –ó–¥–µ—Å—å –º–æ–∂–Ω–æ –¥–æ–±–∞–≤–∏—Ç—å –∑–∞–ø—Ä–æ—Å –∫ Google API –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è
        println!("üí° –î–ª—è –ø–æ–ª–Ω–æ–≥–æ —Å—Ä–∞–≤–Ω–µ–Ω–∏—è –∑–∞–ø—É—Å—Ç–∏—Ç–µ: cargo test test_ml_calibrated_tokenizer_accuracy --features=full");
    } else {
        println!("\nüí° –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ GOOGLE_API_KEY –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è —Å —Ä–µ–∞–ª—å–Ω—ã–º API Google");
    }
    
    println!("\nüéØ –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è: –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ ML-–∫–∞–ª–∏–±—Ä–æ–≤–∞–Ω–Ω—ã–π —Ç–æ–∫–µ–Ω–∏–∑–∞—Ç–æ—Ä –¥–ª—è –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–π —Ç–æ—á–Ω–æ—Å—Ç–∏!");
}