// tests/smart_parallel_test.rs

use gemini_proxy::tokenizer;
use std::time::Instant;

/// –¢–µ—Å—Ç —É–º–Ω–æ–π –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏
#[tokio::test]
async fn test_smart_parallel_logic() {
    println!("\nüß† SMART PARALLEL TOKENIZER TEST\n");
    
    // –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º ML-—Ç–æ–∫–µ–Ω–∏–∑–∞—Ç–æ—Ä (–Ω—É–∂–µ–Ω –¥–ª—è —Ç–æ—á–Ω–æ–≥–æ –ø–æ–¥—Å—á–µ—Ç–∞)
    tokenizer::gemini_ml_calibrated::GeminiMLCalibratedTokenizer::initialize().await.unwrap();
    
    // –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º —É–º–Ω—ã–π –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω—ã–π —Ç–æ–∫–µ–Ω–∏–∑–∞—Ç–æ—Ä
    let config = tokenizer::SmartParallelConfig {
        token_limit: 250_000,
        safe_threshold: 150_000,        // 60% –æ—Ç –ª–∏–º–∏—Ç–∞ (–±–æ–ª–µ–µ –∫–æ–Ω—Å–µ—Ä–≤–∞—Ç–∏–≤–Ω–æ)
        chars_per_token_conservative: 2.0, // –û—á–µ–Ω—å –∫–æ–Ω—Å–µ—Ä–≤–∞—Ç–∏–≤–Ω–∞—è –æ—Ü–µ–Ω–∫–∞
        precise_tokenization_timeout_ms: 100,
        enable_parallel_sending: true,
    };
    
    tokenizer::smart_parallel::SmartParallelTokenizer::initialize(Some(config)).unwrap();
    let tokenizer = tokenizer::get_smart_parallel_tokenizer().unwrap();
    
    // –°–æ–∑–¥–∞–µ–º —Ç–µ—Å—Ç–æ–≤—ã–µ —Ç–µ–∫—Å—Ç—ã
    let small_text = "Hello world!";
    let medium_text = "Hello world! ".repeat(15_000);  // ~180k —Å–∏–º–≤–æ–ª–æ–≤
    let large_text = "Hello world! ".repeat(25_000);   // ~300k —Å–∏–º–≤–æ–ª–æ–≤  
    let huge_text = "Hello world! ".repeat(100_000);   // ~1.2M —Å–∏–º–≤–æ–ª–æ–≤
    
    // –¢–µ—Å—Ç–æ–≤—ã–µ —Å–ª—É—á–∞–∏
    let test_cases = vec![
        ("–ú–∞–ª–µ–Ω—å–∫–∏–π —Ç–µ–∫—Å—Ç", small_text, "SendDirectly"),
        ("–°—Ä–µ–¥–Ω–∏–π —Ç–µ–∫—Å—Ç", medium_text.as_str(), "SendDirectly"),
        ("–ë–æ–ª—å—à–æ–π —Ç–µ–∫—Å—Ç", large_text.as_str(), "ParallelProcessing"),
        ("–û–≥—Ä–æ–º–Ω—ã–π —Ç–µ–∫—Å—Ç", huge_text.as_str(), "RejectImmediately"),
    ];
    
    println!("{:<20} | {:>12} | {:>12} | {:>20}", 
        "–¢–∏–ø —Ç–µ–∫—Å—Ç–∞", "–°–∏–º–≤–æ–ª—ã", "–û—Ü–µ–Ω–∫–∞ —Ç–æ–∫–µ–Ω–æ–≤", "–†–µ—à–µ–Ω–∏–µ");
    println!("{:-<20}-+-{:->12}-+-{:->12}-+-{:->20}", "", "", "", "");
    
    for (name, text, expected_decision) in test_cases {
        let decision = tokenizer.make_processing_decision(text);
        
        let (estimated_tokens, decision_type) = match decision {
            tokenizer::ProcessingDecision::SendDirectly { estimated_tokens } => 
                (estimated_tokens, "SendDirectly"),
            tokenizer::ProcessingDecision::ParallelProcessing { estimated_tokens } => 
                (estimated_tokens, "ParallelProcessing"),
            tokenizer::ProcessingDecision::RejectImmediately { estimated_tokens } => 
                (estimated_tokens, "RejectImmediately"),
        };
        
        println!("{:<20} | {:>12} | {:>12} | {:>20}", 
            name, text.len(), estimated_tokens, decision_type);
        
        // –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ —Ä–µ—à–µ–Ω–∏–µ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É–µ—Ç –æ–∂–∏–¥–∞–Ω–∏—è–º
        assert_eq!(decision_type, expected_decision, 
            "Wrong decision for {name}: expected {expected_decision}, got {decision_type}");
    }
    
    println!("\n‚úÖ –í—Å–µ —Ä–µ—à–µ–Ω–∏—è –ø—Ä–∏–Ω—è—Ç—ã –ø—Ä–∞–≤–∏–ª—å–Ω–æ!");
}

/// –¢–µ—Å—Ç –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Å —Ä–µ–∞–ª—å–Ω–æ–π –æ—Ç–ø—Ä–∞–≤–∫–æ–π
#[tokio::test]
async fn test_parallel_processing_performance() {
    println!("\n‚ö° PARALLEL PROCESSING PERFORMANCE TEST\n");
    
    // –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º —Ç–æ–∫–µ–Ω–∏–∑–∞—Ç–æ—Ä—ã
    tokenizer::gemini_ml_calibrated::GeminiMLCalibratedTokenizer::initialize().await.unwrap();
    tokenizer::smart_parallel::SmartParallelTokenizer::initialize(None).unwrap();
    
    // –¢–µ–∫—Å—Ç –≤ "—Å–µ—Ä–æ–π –∑–æ–Ω–µ" - —Ç—Ä–µ–±—É–µ—Ç –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏
    let test_text = "This is a comprehensive test document. ".repeat(10_000); // ~400k —Å–∏–º–≤–æ–ª–æ–≤ = ~200k —Ç–æ–∫–µ–Ω–æ–≤
    println!("Test text: {} characters", test_text.len());
    
    // –ú–æ–∫ —Ñ—É–Ω–∫—Ü–∏—è –æ—Ç–ø—Ä–∞–≤–∫–∏ —Å —Ä–µ–∞–ª–∏—Å—Ç–∏—á–Ω–æ–π –∑–∞–¥–µ—Ä–∂–∫–æ–π
    let send_function = |text: String| async move {
        let delay = std::cmp::min(100 + text.len() / 10000, 500); // 100-500ms –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç —Ä–∞–∑–º–µ—Ä–∞
        tokio::time::sleep(tokio::time::Duration::from_millis(delay as u64)).await;
        Ok(format!("Mock response for {} chars", text.len()))
    };
    
    let start_time = Instant::now();
    
    let result = tokenizer::process_text_smart(&test_text, send_function).await;
    
    let _total_time = start_time.elapsed();
    
    match result {
        Ok((response, processing_result)) => {
            println!("‚úÖ Parallel processing successful!");
            println!("Response: {response}");
            println!("\nPerformance metrics:");
            println!("  Decision time:      {}ms", processing_result.decision_time_ms);
            println!("  Tokenization time:  {}ms", 
                processing_result.tokenization_time_ms.unwrap_or(0));
            println!("  Network time:       {}ms", 
                processing_result.network_time_ms.unwrap_or(0));
            println!("  Total time:         {}ms", processing_result.total_time_ms);
            println!("  Was parallel:       {}", processing_result.was_parallel);
            println!("  Estimated tokens:   {}", processing_result.estimated_tokens);
            println!("  Actual tokens:      {:?}", processing_result.actual_tokens);
            
            // –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –¥–µ–π—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–æ –±—ã—Å—Ç—Ä–µ–µ
            assert!(processing_result.was_parallel, "Should use parallel processing");
            assert!(processing_result.total_time_ms < 600, 
                "Parallel processing should be fast, took {}ms", processing_result.total_time_ms);
            
            // –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ —Ç–æ–∫–µ–Ω–∏–∑–∞—Ü–∏—è –∏ —Å–µ—Ç—å –≤—ã–ø–æ–ª–Ω—è–ª–∏—Å—å –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ
            let tokenization_time = processing_result.tokenization_time_ms.unwrap_or(0);
            let network_time = processing_result.network_time_ms.unwrap_or(0);
            let expected_sequential_time = tokenization_time + network_time;
            
            println!("\nParallel efficiency:");
            println!("  Sequential would take: {expected_sequential_time}ms");
            println!("  Parallel took:         {}ms", processing_result.total_time_ms);
            println!("  Time saved:            {}ms", 
                expected_sequential_time.saturating_sub(processing_result.total_time_ms));
            
            // –ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –¥–æ–ª–∂–Ω–∞ –±—ã—Ç—å –±—ã—Å—Ç—Ä–µ–µ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ–π
            assert!(processing_result.total_time_ms <= expected_sequential_time,
                "Parallel should be faster than sequential");
        }
        Err(e) => {
            panic!("Parallel processing failed: {e}");
        }
    }
    
    println!("\n‚úÖ Parallel processing performance test passed!");
}

// –¢–µ—Å—Ç –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏ —É–¥–∞–ª–µ–Ω - —ç—Ç–∞ —Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å –ø—Ä–æ—Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∞ –≤ unit-—Ç–µ—Å—Ç–∞—Ö

/// –¢–µ—Å—Ç –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ vs —Ç—Ä–∞–¥–∏—Ü–∏–æ–Ω–Ω–æ–≥–æ –ø–æ–¥—Ö–æ–¥–∞
#[tokio::test]
async fn test_performance_vs_traditional() {
    println!("\nüèÅ PERFORMANCE COMPARISON: Smart Parallel vs Traditional\n");
    
    // –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º —Ç–æ–∫–µ–Ω–∏–∑–∞—Ç–æ—Ä—ã
    tokenizer::gemini_ml_calibrated::GeminiMLCalibratedTokenizer::initialize().await.unwrap();
    tokenizer::smart_parallel::SmartParallelTokenizer::initialize(None).unwrap();
    
    // –¢–µ—Å—Ç –Ω–∞ —Ç–µ–∫—Å—Ç–µ —Å—Ä–µ–¥–Ω–µ–π —Å–ª–æ–∂–Ω–æ—Å—Ç–∏ (~100k —Ç–æ–∫–µ–Ω–æ–≤)
    let test_text = "This is a comprehensive test document with various content. ".repeat(8_000);
    println!("Test text: {} characters (~100k tokens)", test_text.len());
    
    // –ú–æ–∫ —Ñ—É–Ω–∫—Ü–∏—è –æ—Ç–ø—Ä–∞–≤–∫–∏
    let create_send_function = || {
        |text: String| async move {
            let delay = 200 + text.len() / 10000; // –†–µ–∞–ª–∏—Å—Ç–∏—á–Ω–∞—è –∑–∞–¥–µ—Ä–∂–∫–∞
            tokio::time::sleep(tokio::time::Duration::from_millis(delay as u64)).await;
            Ok(format!("Response for {} chars", text.len()))
        }
    };
    
    // 1. –¢—Ä–∞–¥–∏—Ü–∏–æ–Ω–Ω—ã–π –ø–æ–¥—Ö–æ–¥: —Ç–æ–∫–µ–Ω–∏–∑–∞—Ü–∏—è ‚Üí –æ—Ç–ø—Ä–∞–≤–∫–∞
    println!("1. Traditional Approach (Sequential):");
    let start = Instant::now();
    
    let tokenization_start = Instant::now();
    let _token_count = tokenizer::count_ml_calibrated_gemini_tokens(&test_text).unwrap();
    let tokenization_time = tokenization_start.elapsed();
    
    let network_start = Instant::now();
    let _traditional_result = create_send_function()(test_text.clone()).await.unwrap();
    let network_time = network_start.elapsed();
    
    let traditional_total = start.elapsed();
    
    println!("   Tokenization: {:>6}ms", tokenization_time.as_millis());
    println!("   Network:      {:>6}ms", network_time.as_millis());
    println!("   TOTAL:        {:>6}ms", traditional_total.as_millis());
    
    // 2. Smart Parallel –ø–æ–¥—Ö–æ–¥
    println!("\n2. Smart Parallel Approach:");
    let start = Instant::now();
    
    let result = tokenizer::process_text_smart(&test_text, create_send_function()).await.unwrap();
    let smart_total = start.elapsed();
    
    let (_, processing_result) = result;
    
    println!("   Decision:     {:>6}ms", processing_result.decision_time_ms);
    println!("   Tokenization: {:>6}ms", processing_result.tokenization_time_ms.unwrap_or(0));
    println!("   Network:      {:>6}ms", processing_result.network_time_ms.unwrap_or(0));
    println!("   TOTAL:        {:>6}ms", processing_result.total_time_ms);
    println!("   Parallel:     {}", processing_result.was_parallel);
    
    // –ê–Ω–∞–ª–∏–∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
    println!("\nüìä Performance Analysis:");
    let time_saved = traditional_total.as_millis() as i64 - smart_total.as_millis() as i64;
    let speedup = traditional_total.as_millis() as f64 / smart_total.as_millis() as f64;
    
    println!("   Traditional:  {:>6}ms", traditional_total.as_millis());
    println!("   Smart:        {:>6}ms", smart_total.as_millis());
    println!("   Time saved:   {time_saved:>6}ms");
    println!("   Speedup:      {speedup:>6.2}x");
    
    // Smart –ø–æ–¥—Ö–æ–¥ –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –±—ã—Å—Ç—Ä–µ–µ –∏–ª–∏ —Ä–∞–≤–µ–Ω —Ç—Ä–∞–¥–∏—Ü–∏–æ–Ω–Ω–æ–º—É,
    // –Ω–æ –º—ã –¥–æ–±–∞–≤–ª—è–µ–º –Ω–µ–±–æ–ª—å—à–æ–π –¥–æ–ø—É—Å–∫ (–Ω–∞–ø—Ä–∏–º–µ—Ä, 50 –º—Å) –¥–ª—è —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç–∏ —Ç–µ—Å—Ç–∞,
    // —á—Ç–æ–±—ã –∏–∑–±–µ–∂–∞—Ç—å –ª–æ–∂–Ω—ã—Ö —Å—Ä–∞–±–∞—Ç—ã–≤–∞–Ω–∏–π –∏–∑-–∑–∞ —Å–∏—Å—Ç–µ–º–Ω–æ–≥–æ "—à—É–º–∞".
    let tolerance = std::time::Duration::from_millis(50);
    assert!(smart_total <= traditional_total + tolerance,
        "Smart parallel should be faster or equal to traditional (with tolerance)");
    
    println!("\n‚úÖ Smart Parallel is {speedup}x faster!");
}